{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f33fb71",
   "metadata": {},
   "source": [
    "# ðŸš€ Detect AI vs. Human-Generated Images  \n",
    "\n",
    "### ðŸ“Œ **Competition Overview**  \n",
    "[ðŸ”— **Kaggle Competition Link**](https://www.kaggle.com/competitions/detect-ai-vs-human-generated-images/overview)  \n",
    "\n",
    "This challenge focuses on distinguishing **AI-generated images** from **human-created** onesâ€”a critical task in todayâ€™s digital landscape where deepfakes and synthetic media are rapidly evolving. Participants will develop ML models to classify images accurately while ensuring fairness and robustness.  \n",
    "\n",
    "### ðŸŽ¯ **Key Objectives**  \n",
    "âœ” **Detect AI-generated vs. human-created images** using a balanced dataset.  \n",
    "âœ” **Promote fairness & inclusivity** in AI by encouraging diverse participation.  \n",
    "âœ” **Enhance deepfake detection** to combat misinformation and uphold media authenticity.  \n",
    "âœ” **Foster innovation** through hands-on experience with real-world datasets.  \n",
    "\n",
    "\n",
    "### ðŸ’¡ **Why Join?**  \n",
    "The reason why I'm tackling this project is to further my understanding of image classfication and to gain practical ML experience with industry-grade data. This will also help me to build a portfolio of projects that I can showcase to potential employers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f35a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6da86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Device-agnostic setup.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5820e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory and CSV path.\n",
    "base_dir = \"data/detect-ai-vs-human-generated-images\"\n",
    "csv_path = os.path.join(base_dir, \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54eb0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation transforms.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f741b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom dataset.\n",
    "from going_modular.custom_dataset import CustomImageDataset\n",
    "\n",
    "# Create the full dataset using training transform.\n",
    "full_dataset = CustomImageDataset(csv_file=csv_path, \n",
    "                                  base_dir=base_dir, \n",
    "                                  transform=train_transform)\n",
    "\n",
    "# Split the dataset into train and validation subsets.\n",
    "train_indices, val_indices = train_test_split(range(len(full_dataset)), \n",
    "                                              test_size=0.05, \n",
    "                                              random_state=42, \n",
    "                                              stratify=pd.read_csv(csv_path)['label'])\n",
    "train_subset = Subset(full_dataset, train_indices)\n",
    "val_subset = Subset(full_dataset, val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders.\n",
    "batch_size = 64    # 128 will require about 27GB of VRAM.\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(train_subset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_subset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_workers, \n",
    "                        pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f932ae",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "From this section, only run one cell that corresponds to the model you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e47e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 trainable parameters:\n",
      "conv1.weight: requires_grad = False\n",
      "bn1.weight: requires_grad = False\n",
      "bn1.bias: requires_grad = False\n",
      "layer1.0.conv1.weight: requires_grad = False\n",
      "layer1.0.bn1.weight: requires_grad = False\n",
      "layer1.0.bn1.bias: requires_grad = False\n",
      "layer1.0.conv2.weight: requires_grad = False\n",
      "layer1.0.bn2.weight: requires_grad = False\n",
      "layer1.0.bn2.bias: requires_grad = False\n",
      "layer1.0.conv3.weight: requires_grad = False\n",
      "layer1.0.bn3.weight: requires_grad = False\n",
      "layer1.0.bn3.bias: requires_grad = False\n",
      "layer1.0.downsample.0.weight: requires_grad = False\n",
      "layer1.0.downsample.1.weight: requires_grad = False\n",
      "layer1.0.downsample.1.bias: requires_grad = False\n",
      "layer1.1.conv1.weight: requires_grad = False\n",
      "layer1.1.bn1.weight: requires_grad = False\n",
      "layer1.1.bn1.bias: requires_grad = False\n",
      "layer1.1.conv2.weight: requires_grad = False\n",
      "layer1.1.bn2.weight: requires_grad = False\n",
      "layer1.1.bn2.bias: requires_grad = False\n",
      "layer1.1.conv3.weight: requires_grad = False\n",
      "layer1.1.bn3.weight: requires_grad = False\n",
      "layer1.1.bn3.bias: requires_grad = False\n",
      "layer1.2.conv1.weight: requires_grad = False\n",
      "layer1.2.bn1.weight: requires_grad = False\n",
      "layer1.2.bn1.bias: requires_grad = False\n",
      "layer1.2.conv2.weight: requires_grad = False\n",
      "layer1.2.bn2.weight: requires_grad = False\n",
      "layer1.2.bn2.bias: requires_grad = False\n",
      "layer1.2.conv3.weight: requires_grad = False\n",
      "layer1.2.bn3.weight: requires_grad = False\n",
      "layer1.2.bn3.bias: requires_grad = False\n",
      "layer2.0.conv1.weight: requires_grad = False\n",
      "layer2.0.bn1.weight: requires_grad = False\n",
      "layer2.0.bn1.bias: requires_grad = False\n",
      "layer2.0.conv2.weight: requires_grad = False\n",
      "layer2.0.bn2.weight: requires_grad = False\n",
      "layer2.0.bn2.bias: requires_grad = False\n",
      "layer2.0.conv3.weight: requires_grad = False\n",
      "layer2.0.bn3.weight: requires_grad = False\n",
      "layer2.0.bn3.bias: requires_grad = False\n",
      "layer2.0.downsample.0.weight: requires_grad = False\n",
      "layer2.0.downsample.1.weight: requires_grad = False\n",
      "layer2.0.downsample.1.bias: requires_grad = False\n",
      "layer2.1.conv1.weight: requires_grad = False\n",
      "layer2.1.bn1.weight: requires_grad = False\n",
      "layer2.1.bn1.bias: requires_grad = False\n",
      "layer2.1.conv2.weight: requires_grad = False\n",
      "layer2.1.bn2.weight: requires_grad = False\n",
      "layer2.1.bn2.bias: requires_grad = False\n",
      "layer2.1.conv3.weight: requires_grad = False\n",
      "layer2.1.bn3.weight: requires_grad = False\n",
      "layer2.1.bn3.bias: requires_grad = False\n",
      "layer2.2.conv1.weight: requires_grad = False\n",
      "layer2.2.bn1.weight: requires_grad = False\n",
      "layer2.2.bn1.bias: requires_grad = False\n",
      "layer2.2.conv2.weight: requires_grad = False\n",
      "layer2.2.bn2.weight: requires_grad = False\n",
      "layer2.2.bn2.bias: requires_grad = False\n",
      "layer2.2.conv3.weight: requires_grad = False\n",
      "layer2.2.bn3.weight: requires_grad = False\n",
      "layer2.2.bn3.bias: requires_grad = False\n",
      "layer2.3.conv1.weight: requires_grad = False\n",
      "layer2.3.bn1.weight: requires_grad = False\n",
      "layer2.3.bn1.bias: requires_grad = False\n",
      "layer2.3.conv2.weight: requires_grad = False\n",
      "layer2.3.bn2.weight: requires_grad = False\n",
      "layer2.3.bn2.bias: requires_grad = False\n",
      "layer2.3.conv3.weight: requires_grad = False\n",
      "layer2.3.bn3.weight: requires_grad = False\n",
      "layer2.3.bn3.bias: requires_grad = False\n",
      "layer3.0.conv1.weight: requires_grad = False\n",
      "layer3.0.bn1.weight: requires_grad = False\n",
      "layer3.0.bn1.bias: requires_grad = False\n",
      "layer3.0.conv2.weight: requires_grad = False\n",
      "layer3.0.bn2.weight: requires_grad = False\n",
      "layer3.0.bn2.bias: requires_grad = False\n",
      "layer3.0.conv3.weight: requires_grad = False\n",
      "layer3.0.bn3.weight: requires_grad = False\n",
      "layer3.0.bn3.bias: requires_grad = False\n",
      "layer3.0.downsample.0.weight: requires_grad = False\n",
      "layer3.0.downsample.1.weight: requires_grad = False\n",
      "layer3.0.downsample.1.bias: requires_grad = False\n",
      "layer3.1.conv1.weight: requires_grad = False\n",
      "layer3.1.bn1.weight: requires_grad = False\n",
      "layer3.1.bn1.bias: requires_grad = False\n",
      "layer3.1.conv2.weight: requires_grad = False\n",
      "layer3.1.bn2.weight: requires_grad = False\n",
      "layer3.1.bn2.bias: requires_grad = False\n",
      "layer3.1.conv3.weight: requires_grad = False\n",
      "layer3.1.bn3.weight: requires_grad = False\n",
      "layer3.1.bn3.bias: requires_grad = False\n",
      "layer3.2.conv1.weight: requires_grad = False\n",
      "layer3.2.bn1.weight: requires_grad = False\n",
      "layer3.2.bn1.bias: requires_grad = False\n",
      "layer3.2.conv2.weight: requires_grad = False\n",
      "layer3.2.bn2.weight: requires_grad = False\n",
      "layer3.2.bn2.bias: requires_grad = False\n",
      "layer3.2.conv3.weight: requires_grad = False\n",
      "layer3.2.bn3.weight: requires_grad = False\n",
      "layer3.2.bn3.bias: requires_grad = False\n",
      "layer3.3.conv1.weight: requires_grad = False\n",
      "layer3.3.bn1.weight: requires_grad = False\n",
      "layer3.3.bn1.bias: requires_grad = False\n",
      "layer3.3.conv2.weight: requires_grad = False\n",
      "layer3.3.bn2.weight: requires_grad = False\n",
      "layer3.3.bn2.bias: requires_grad = False\n",
      "layer3.3.conv3.weight: requires_grad = False\n",
      "layer3.3.bn3.weight: requires_grad = False\n",
      "layer3.3.bn3.bias: requires_grad = False\n",
      "layer3.4.conv1.weight: requires_grad = False\n",
      "layer3.4.bn1.weight: requires_grad = False\n",
      "layer3.4.bn1.bias: requires_grad = False\n",
      "layer3.4.conv2.weight: requires_grad = False\n",
      "layer3.4.bn2.weight: requires_grad = False\n",
      "layer3.4.bn2.bias: requires_grad = False\n",
      "layer3.4.conv3.weight: requires_grad = False\n",
      "layer3.4.bn3.weight: requires_grad = False\n",
      "layer3.4.bn3.bias: requires_grad = False\n",
      "layer3.5.conv1.weight: requires_grad = False\n",
      "layer3.5.bn1.weight: requires_grad = False\n",
      "layer3.5.bn1.bias: requires_grad = False\n",
      "layer3.5.conv2.weight: requires_grad = False\n",
      "layer3.5.bn2.weight: requires_grad = False\n",
      "layer3.5.bn2.bias: requires_grad = False\n",
      "layer3.5.conv3.weight: requires_grad = False\n",
      "layer3.5.bn3.weight: requires_grad = False\n",
      "layer3.5.bn3.bias: requires_grad = False\n",
      "layer4.0.conv1.weight: requires_grad = True\n",
      "layer4.0.bn1.weight: requires_grad = True\n",
      "layer4.0.bn1.bias: requires_grad = True\n",
      "layer4.0.conv2.weight: requires_grad = True\n",
      "layer4.0.bn2.weight: requires_grad = True\n",
      "layer4.0.bn2.bias: requires_grad = True\n",
      "layer4.0.conv3.weight: requires_grad = True\n",
      "layer4.0.bn3.weight: requires_grad = True\n",
      "layer4.0.bn3.bias: requires_grad = True\n",
      "layer4.0.downsample.0.weight: requires_grad = True\n",
      "layer4.0.downsample.1.weight: requires_grad = True\n",
      "layer4.0.downsample.1.bias: requires_grad = True\n",
      "layer4.1.conv1.weight: requires_grad = True\n",
      "layer4.1.bn1.weight: requires_grad = True\n",
      "layer4.1.bn1.bias: requires_grad = True\n",
      "layer4.1.conv2.weight: requires_grad = True\n",
      "layer4.1.bn2.weight: requires_grad = True\n",
      "layer4.1.bn2.bias: requires_grad = True\n",
      "layer4.1.conv3.weight: requires_grad = True\n",
      "layer4.1.bn3.weight: requires_grad = True\n",
      "layer4.1.bn3.bias: requires_grad = True\n",
      "layer4.2.conv1.weight: requires_grad = True\n",
      "layer4.2.bn1.weight: requires_grad = True\n",
      "layer4.2.bn1.bias: requires_grad = True\n",
      "layer4.2.conv2.weight: requires_grad = True\n",
      "layer4.2.bn2.weight: requires_grad = True\n",
      "layer4.2.bn2.bias: requires_grad = True\n",
      "layer4.2.conv3.weight: requires_grad = True\n",
      "layer4.2.bn3.weight: requires_grad = True\n",
      "layer4.2.bn3.bias: requires_grad = True\n",
      "fc.weight: requires_grad = True\n",
      "fc.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_model_resnet50(num_classes=2, num_freeze_layers=1):\n",
    "    \"\"\"\n",
    "    Creates a ResNet50 model (a standard CNN) with pretrained weights.\n",
    "    \n",
    "    The model is modified to output `num_classes` classes.\n",
    "    The variable `num_freeze_layers` controls how many of the initial\n",
    "    blocks are frozen. In ResNet50, we assume that by default we want\n",
    "    only the last block (layer4) and the fully connected (fc) head trainable.\n",
    "    \n",
    "    Parameters:\n",
    "      - num_classes (int): number of output classes.\n",
    "      - num_freeze_layers (int): number of blocks (starting from the first) \n",
    "                                 whose parameters will be frozen. \n",
    "                                 Default is 1 (freeze all except 'layer4' and 'fc').\n",
    "    \n",
    "    Returns:\n",
    "      - model (nn.Module): The modified ResNet50 model.\n",
    "    \"\"\"\n",
    "    model = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    # For ResNet50 the children are typically: conv1, bn1, layer1, layer2, layer3, layer4, fc.\n",
    "    # Here we freeze all blocks except the last \"layer4\" and the classifier \"fc\".\n",
    "    if num_freeze_layers >= 1:\n",
    "        for name, module in model.named_children():\n",
    "            if name not in ['layer4', 'fc']:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "    return model\n",
    "  \n",
    "  \n",
    "# Set the number of blocks to keep trainable.\n",
    "num_freeze_layers = 1\n",
    "\n",
    "# Initialize ResNet50 model.\n",
    "resnet_model = get_model_resnet50(num_classes=2, num_freeze_layers=num_freeze_layers)\n",
    "\n",
    "# Example: Print out which parameters are trainable.\n",
    "print(\"ResNet50 trainable parameters:\")\n",
    "for name, param in resnet_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ef934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet-B3 trainable parameters:\n",
      "conv_stem.weight: requires_grad = True\n",
      "bn1.weight: requires_grad = True\n",
      "bn1.bias: requires_grad = True\n",
      "blocks.0.0.conv_dw.weight: requires_grad = False\n",
      "blocks.0.0.bn1.weight: requires_grad = False\n",
      "blocks.0.0.bn1.bias: requires_grad = False\n",
      "blocks.0.0.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.0.0.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.0.0.se.conv_expand.weight: requires_grad = False\n",
      "blocks.0.0.se.conv_expand.bias: requires_grad = False\n",
      "blocks.0.0.conv_pw.weight: requires_grad = False\n",
      "blocks.0.0.bn2.weight: requires_grad = False\n",
      "blocks.0.0.bn2.bias: requires_grad = False\n",
      "blocks.0.1.conv_dw.weight: requires_grad = False\n",
      "blocks.0.1.bn1.weight: requires_grad = False\n",
      "blocks.0.1.bn1.bias: requires_grad = False\n",
      "blocks.0.1.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.0.1.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.0.1.se.conv_expand.weight: requires_grad = False\n",
      "blocks.0.1.se.conv_expand.bias: requires_grad = False\n",
      "blocks.0.1.conv_pw.weight: requires_grad = False\n",
      "blocks.0.1.bn2.weight: requires_grad = False\n",
      "blocks.0.1.bn2.bias: requires_grad = False\n",
      "blocks.1.0.conv_pw.weight: requires_grad = False\n",
      "blocks.1.0.bn1.weight: requires_grad = False\n",
      "blocks.1.0.bn1.bias: requires_grad = False\n",
      "blocks.1.0.conv_dw.weight: requires_grad = False\n",
      "blocks.1.0.bn2.weight: requires_grad = False\n",
      "blocks.1.0.bn2.bias: requires_grad = False\n",
      "blocks.1.0.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.1.0.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.1.0.se.conv_expand.weight: requires_grad = False\n",
      "blocks.1.0.se.conv_expand.bias: requires_grad = False\n",
      "blocks.1.0.conv_pwl.weight: requires_grad = False\n",
      "blocks.1.0.bn3.weight: requires_grad = False\n",
      "blocks.1.0.bn3.bias: requires_grad = False\n",
      "blocks.1.1.conv_pw.weight: requires_grad = False\n",
      "blocks.1.1.bn1.weight: requires_grad = False\n",
      "blocks.1.1.bn1.bias: requires_grad = False\n",
      "blocks.1.1.conv_dw.weight: requires_grad = False\n",
      "blocks.1.1.bn2.weight: requires_grad = False\n",
      "blocks.1.1.bn2.bias: requires_grad = False\n",
      "blocks.1.1.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.1.1.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.1.1.se.conv_expand.weight: requires_grad = False\n",
      "blocks.1.1.se.conv_expand.bias: requires_grad = False\n",
      "blocks.1.1.conv_pwl.weight: requires_grad = False\n",
      "blocks.1.1.bn3.weight: requires_grad = False\n",
      "blocks.1.1.bn3.bias: requires_grad = False\n",
      "blocks.1.2.conv_pw.weight: requires_grad = False\n",
      "blocks.1.2.bn1.weight: requires_grad = False\n",
      "blocks.1.2.bn1.bias: requires_grad = False\n",
      "blocks.1.2.conv_dw.weight: requires_grad = False\n",
      "blocks.1.2.bn2.weight: requires_grad = False\n",
      "blocks.1.2.bn2.bias: requires_grad = False\n",
      "blocks.1.2.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.1.2.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.1.2.se.conv_expand.weight: requires_grad = False\n",
      "blocks.1.2.se.conv_expand.bias: requires_grad = False\n",
      "blocks.1.2.conv_pwl.weight: requires_grad = False\n",
      "blocks.1.2.bn3.weight: requires_grad = False\n",
      "blocks.1.2.bn3.bias: requires_grad = False\n",
      "blocks.2.0.conv_pw.weight: requires_grad = False\n",
      "blocks.2.0.bn1.weight: requires_grad = False\n",
      "blocks.2.0.bn1.bias: requires_grad = False\n",
      "blocks.2.0.conv_dw.weight: requires_grad = False\n",
      "blocks.2.0.bn2.weight: requires_grad = False\n",
      "blocks.2.0.bn2.bias: requires_grad = False\n",
      "blocks.2.0.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.2.0.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.2.0.se.conv_expand.weight: requires_grad = False\n",
      "blocks.2.0.se.conv_expand.bias: requires_grad = False\n",
      "blocks.2.0.conv_pwl.weight: requires_grad = False\n",
      "blocks.2.0.bn3.weight: requires_grad = False\n",
      "blocks.2.0.bn3.bias: requires_grad = False\n",
      "blocks.2.1.conv_pw.weight: requires_grad = False\n",
      "blocks.2.1.bn1.weight: requires_grad = False\n",
      "blocks.2.1.bn1.bias: requires_grad = False\n",
      "blocks.2.1.conv_dw.weight: requires_grad = False\n",
      "blocks.2.1.bn2.weight: requires_grad = False\n",
      "blocks.2.1.bn2.bias: requires_grad = False\n",
      "blocks.2.1.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.2.1.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.2.1.se.conv_expand.weight: requires_grad = False\n",
      "blocks.2.1.se.conv_expand.bias: requires_grad = False\n",
      "blocks.2.1.conv_pwl.weight: requires_grad = False\n",
      "blocks.2.1.bn3.weight: requires_grad = False\n",
      "blocks.2.1.bn3.bias: requires_grad = False\n",
      "blocks.2.2.conv_pw.weight: requires_grad = False\n",
      "blocks.2.2.bn1.weight: requires_grad = False\n",
      "blocks.2.2.bn1.bias: requires_grad = False\n",
      "blocks.2.2.conv_dw.weight: requires_grad = False\n",
      "blocks.2.2.bn2.weight: requires_grad = False\n",
      "blocks.2.2.bn2.bias: requires_grad = False\n",
      "blocks.2.2.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.2.2.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.2.2.se.conv_expand.weight: requires_grad = False\n",
      "blocks.2.2.se.conv_expand.bias: requires_grad = False\n",
      "blocks.2.2.conv_pwl.weight: requires_grad = False\n",
      "blocks.2.2.bn3.weight: requires_grad = False\n",
      "blocks.2.2.bn3.bias: requires_grad = False\n",
      "blocks.3.0.conv_pw.weight: requires_grad = False\n",
      "blocks.3.0.bn1.weight: requires_grad = False\n",
      "blocks.3.0.bn1.bias: requires_grad = False\n",
      "blocks.3.0.conv_dw.weight: requires_grad = False\n",
      "blocks.3.0.bn2.weight: requires_grad = False\n",
      "blocks.3.0.bn2.bias: requires_grad = False\n",
      "blocks.3.0.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.3.0.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.3.0.se.conv_expand.weight: requires_grad = False\n",
      "blocks.3.0.se.conv_expand.bias: requires_grad = False\n",
      "blocks.3.0.conv_pwl.weight: requires_grad = False\n",
      "blocks.3.0.bn3.weight: requires_grad = False\n",
      "blocks.3.0.bn3.bias: requires_grad = False\n",
      "blocks.3.1.conv_pw.weight: requires_grad = False\n",
      "blocks.3.1.bn1.weight: requires_grad = False\n",
      "blocks.3.1.bn1.bias: requires_grad = False\n",
      "blocks.3.1.conv_dw.weight: requires_grad = False\n",
      "blocks.3.1.bn2.weight: requires_grad = False\n",
      "blocks.3.1.bn2.bias: requires_grad = False\n",
      "blocks.3.1.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.3.1.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.3.1.se.conv_expand.weight: requires_grad = False\n",
      "blocks.3.1.se.conv_expand.bias: requires_grad = False\n",
      "blocks.3.1.conv_pwl.weight: requires_grad = False\n",
      "blocks.3.1.bn3.weight: requires_grad = False\n",
      "blocks.3.1.bn3.bias: requires_grad = False\n",
      "blocks.3.2.conv_pw.weight: requires_grad = False\n",
      "blocks.3.2.bn1.weight: requires_grad = False\n",
      "blocks.3.2.bn1.bias: requires_grad = False\n",
      "blocks.3.2.conv_dw.weight: requires_grad = False\n",
      "blocks.3.2.bn2.weight: requires_grad = False\n",
      "blocks.3.2.bn2.bias: requires_grad = False\n",
      "blocks.3.2.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.3.2.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.3.2.se.conv_expand.weight: requires_grad = False\n",
      "blocks.3.2.se.conv_expand.bias: requires_grad = False\n",
      "blocks.3.2.conv_pwl.weight: requires_grad = False\n",
      "blocks.3.2.bn3.weight: requires_grad = False\n",
      "blocks.3.2.bn3.bias: requires_grad = False\n",
      "blocks.3.3.conv_pw.weight: requires_grad = False\n",
      "blocks.3.3.bn1.weight: requires_grad = False\n",
      "blocks.3.3.bn1.bias: requires_grad = False\n",
      "blocks.3.3.conv_dw.weight: requires_grad = False\n",
      "blocks.3.3.bn2.weight: requires_grad = False\n",
      "blocks.3.3.bn2.bias: requires_grad = False\n",
      "blocks.3.3.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.3.3.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.3.3.se.conv_expand.weight: requires_grad = False\n",
      "blocks.3.3.se.conv_expand.bias: requires_grad = False\n",
      "blocks.3.3.conv_pwl.weight: requires_grad = False\n",
      "blocks.3.3.bn3.weight: requires_grad = False\n",
      "blocks.3.3.bn3.bias: requires_grad = False\n",
      "blocks.3.4.conv_pw.weight: requires_grad = False\n",
      "blocks.3.4.bn1.weight: requires_grad = False\n",
      "blocks.3.4.bn1.bias: requires_grad = False\n",
      "blocks.3.4.conv_dw.weight: requires_grad = False\n",
      "blocks.3.4.bn2.weight: requires_grad = False\n",
      "blocks.3.4.bn2.bias: requires_grad = False\n",
      "blocks.3.4.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.3.4.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.3.4.se.conv_expand.weight: requires_grad = False\n",
      "blocks.3.4.se.conv_expand.bias: requires_grad = False\n",
      "blocks.3.4.conv_pwl.weight: requires_grad = False\n",
      "blocks.3.4.bn3.weight: requires_grad = False\n",
      "blocks.3.4.bn3.bias: requires_grad = False\n",
      "blocks.4.0.conv_pw.weight: requires_grad = False\n",
      "blocks.4.0.bn1.weight: requires_grad = False\n",
      "blocks.4.0.bn1.bias: requires_grad = False\n",
      "blocks.4.0.conv_dw.weight: requires_grad = False\n",
      "blocks.4.0.bn2.weight: requires_grad = False\n",
      "blocks.4.0.bn2.bias: requires_grad = False\n",
      "blocks.4.0.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.4.0.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.4.0.se.conv_expand.weight: requires_grad = False\n",
      "blocks.4.0.se.conv_expand.bias: requires_grad = False\n",
      "blocks.4.0.conv_pwl.weight: requires_grad = False\n",
      "blocks.4.0.bn3.weight: requires_grad = False\n",
      "blocks.4.0.bn3.bias: requires_grad = False\n",
      "blocks.4.1.conv_pw.weight: requires_grad = False\n",
      "blocks.4.1.bn1.weight: requires_grad = False\n",
      "blocks.4.1.bn1.bias: requires_grad = False\n",
      "blocks.4.1.conv_dw.weight: requires_grad = False\n",
      "blocks.4.1.bn2.weight: requires_grad = False\n",
      "blocks.4.1.bn2.bias: requires_grad = False\n",
      "blocks.4.1.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.4.1.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.4.1.se.conv_expand.weight: requires_grad = False\n",
      "blocks.4.1.se.conv_expand.bias: requires_grad = False\n",
      "blocks.4.1.conv_pwl.weight: requires_grad = False\n",
      "blocks.4.1.bn3.weight: requires_grad = False\n",
      "blocks.4.1.bn3.bias: requires_grad = False\n",
      "blocks.4.2.conv_pw.weight: requires_grad = False\n",
      "blocks.4.2.bn1.weight: requires_grad = False\n",
      "blocks.4.2.bn1.bias: requires_grad = False\n",
      "blocks.4.2.conv_dw.weight: requires_grad = False\n",
      "blocks.4.2.bn2.weight: requires_grad = False\n",
      "blocks.4.2.bn2.bias: requires_grad = False\n",
      "blocks.4.2.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.4.2.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.4.2.se.conv_expand.weight: requires_grad = False\n",
      "blocks.4.2.se.conv_expand.bias: requires_grad = False\n",
      "blocks.4.2.conv_pwl.weight: requires_grad = False\n",
      "blocks.4.2.bn3.weight: requires_grad = False\n",
      "blocks.4.2.bn3.bias: requires_grad = False\n",
      "blocks.4.3.conv_pw.weight: requires_grad = False\n",
      "blocks.4.3.bn1.weight: requires_grad = False\n",
      "blocks.4.3.bn1.bias: requires_grad = False\n",
      "blocks.4.3.conv_dw.weight: requires_grad = False\n",
      "blocks.4.3.bn2.weight: requires_grad = False\n",
      "blocks.4.3.bn2.bias: requires_grad = False\n",
      "blocks.4.3.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.4.3.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.4.3.se.conv_expand.weight: requires_grad = False\n",
      "blocks.4.3.se.conv_expand.bias: requires_grad = False\n",
      "blocks.4.3.conv_pwl.weight: requires_grad = False\n",
      "blocks.4.3.bn3.weight: requires_grad = False\n",
      "blocks.4.3.bn3.bias: requires_grad = False\n",
      "blocks.4.4.conv_pw.weight: requires_grad = False\n",
      "blocks.4.4.bn1.weight: requires_grad = False\n",
      "blocks.4.4.bn1.bias: requires_grad = False\n",
      "blocks.4.4.conv_dw.weight: requires_grad = False\n",
      "blocks.4.4.bn2.weight: requires_grad = False\n",
      "blocks.4.4.bn2.bias: requires_grad = False\n",
      "blocks.4.4.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.4.4.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.4.4.se.conv_expand.weight: requires_grad = False\n",
      "blocks.4.4.se.conv_expand.bias: requires_grad = False\n",
      "blocks.4.4.conv_pwl.weight: requires_grad = False\n",
      "blocks.4.4.bn3.weight: requires_grad = False\n",
      "blocks.4.4.bn3.bias: requires_grad = False\n",
      "blocks.5.0.conv_pw.weight: requires_grad = False\n",
      "blocks.5.0.bn1.weight: requires_grad = False\n",
      "blocks.5.0.bn1.bias: requires_grad = False\n",
      "blocks.5.0.conv_dw.weight: requires_grad = False\n",
      "blocks.5.0.bn2.weight: requires_grad = False\n",
      "blocks.5.0.bn2.bias: requires_grad = False\n",
      "blocks.5.0.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.5.0.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.5.0.se.conv_expand.weight: requires_grad = False\n",
      "blocks.5.0.se.conv_expand.bias: requires_grad = False\n",
      "blocks.5.0.conv_pwl.weight: requires_grad = False\n",
      "blocks.5.0.bn3.weight: requires_grad = False\n",
      "blocks.5.0.bn3.bias: requires_grad = False\n",
      "blocks.5.1.conv_pw.weight: requires_grad = False\n",
      "blocks.5.1.bn1.weight: requires_grad = False\n",
      "blocks.5.1.bn1.bias: requires_grad = False\n",
      "blocks.5.1.conv_dw.weight: requires_grad = False\n",
      "blocks.5.1.bn2.weight: requires_grad = False\n",
      "blocks.5.1.bn2.bias: requires_grad = False\n",
      "blocks.5.1.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.5.1.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.5.1.se.conv_expand.weight: requires_grad = False\n",
      "blocks.5.1.se.conv_expand.bias: requires_grad = False\n",
      "blocks.5.1.conv_pwl.weight: requires_grad = False\n",
      "blocks.5.1.bn3.weight: requires_grad = False\n",
      "blocks.5.1.bn3.bias: requires_grad = False\n",
      "blocks.5.2.conv_pw.weight: requires_grad = False\n",
      "blocks.5.2.bn1.weight: requires_grad = False\n",
      "blocks.5.2.bn1.bias: requires_grad = False\n",
      "blocks.5.2.conv_dw.weight: requires_grad = False\n",
      "blocks.5.2.bn2.weight: requires_grad = False\n",
      "blocks.5.2.bn2.bias: requires_grad = False\n",
      "blocks.5.2.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.5.2.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.5.2.se.conv_expand.weight: requires_grad = False\n",
      "blocks.5.2.se.conv_expand.bias: requires_grad = False\n",
      "blocks.5.2.conv_pwl.weight: requires_grad = False\n",
      "blocks.5.2.bn3.weight: requires_grad = False\n",
      "blocks.5.2.bn3.bias: requires_grad = False\n",
      "blocks.5.3.conv_pw.weight: requires_grad = False\n",
      "blocks.5.3.bn1.weight: requires_grad = False\n",
      "blocks.5.3.bn1.bias: requires_grad = False\n",
      "blocks.5.3.conv_dw.weight: requires_grad = False\n",
      "blocks.5.3.bn2.weight: requires_grad = False\n",
      "blocks.5.3.bn2.bias: requires_grad = False\n",
      "blocks.5.3.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.5.3.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.5.3.se.conv_expand.weight: requires_grad = False\n",
      "blocks.5.3.se.conv_expand.bias: requires_grad = False\n",
      "blocks.5.3.conv_pwl.weight: requires_grad = False\n",
      "blocks.5.3.bn3.weight: requires_grad = False\n",
      "blocks.5.3.bn3.bias: requires_grad = False\n",
      "blocks.5.4.conv_pw.weight: requires_grad = False\n",
      "blocks.5.4.bn1.weight: requires_grad = False\n",
      "blocks.5.4.bn1.bias: requires_grad = False\n",
      "blocks.5.4.conv_dw.weight: requires_grad = False\n",
      "blocks.5.4.bn2.weight: requires_grad = False\n",
      "blocks.5.4.bn2.bias: requires_grad = False\n",
      "blocks.5.4.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.5.4.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.5.4.se.conv_expand.weight: requires_grad = False\n",
      "blocks.5.4.se.conv_expand.bias: requires_grad = False\n",
      "blocks.5.4.conv_pwl.weight: requires_grad = False\n",
      "blocks.5.4.bn3.weight: requires_grad = False\n",
      "blocks.5.4.bn3.bias: requires_grad = False\n",
      "blocks.5.5.conv_pw.weight: requires_grad = False\n",
      "blocks.5.5.bn1.weight: requires_grad = False\n",
      "blocks.5.5.bn1.bias: requires_grad = False\n",
      "blocks.5.5.conv_dw.weight: requires_grad = False\n",
      "blocks.5.5.bn2.weight: requires_grad = False\n",
      "blocks.5.5.bn2.bias: requires_grad = False\n",
      "blocks.5.5.se.conv_reduce.weight: requires_grad = False\n",
      "blocks.5.5.se.conv_reduce.bias: requires_grad = False\n",
      "blocks.5.5.se.conv_expand.weight: requires_grad = False\n",
      "blocks.5.5.se.conv_expand.bias: requires_grad = False\n",
      "blocks.5.5.conv_pwl.weight: requires_grad = False\n",
      "blocks.5.5.bn3.weight: requires_grad = False\n",
      "blocks.5.5.bn3.bias: requires_grad = False\n",
      "blocks.6.0.conv_pw.weight: requires_grad = True\n",
      "blocks.6.0.bn1.weight: requires_grad = True\n",
      "blocks.6.0.bn1.bias: requires_grad = True\n",
      "blocks.6.0.conv_dw.weight: requires_grad = True\n",
      "blocks.6.0.bn2.weight: requires_grad = True\n",
      "blocks.6.0.bn2.bias: requires_grad = True\n",
      "blocks.6.0.se.conv_reduce.weight: requires_grad = True\n",
      "blocks.6.0.se.conv_reduce.bias: requires_grad = True\n",
      "blocks.6.0.se.conv_expand.weight: requires_grad = True\n",
      "blocks.6.0.se.conv_expand.bias: requires_grad = True\n",
      "blocks.6.0.conv_pwl.weight: requires_grad = True\n",
      "blocks.6.0.bn3.weight: requires_grad = True\n",
      "blocks.6.0.bn3.bias: requires_grad = True\n",
      "blocks.6.1.conv_pw.weight: requires_grad = True\n",
      "blocks.6.1.bn1.weight: requires_grad = True\n",
      "blocks.6.1.bn1.bias: requires_grad = True\n",
      "blocks.6.1.conv_dw.weight: requires_grad = True\n",
      "blocks.6.1.bn2.weight: requires_grad = True\n",
      "blocks.6.1.bn2.bias: requires_grad = True\n",
      "blocks.6.1.se.conv_reduce.weight: requires_grad = True\n",
      "blocks.6.1.se.conv_reduce.bias: requires_grad = True\n",
      "blocks.6.1.se.conv_expand.weight: requires_grad = True\n",
      "blocks.6.1.se.conv_expand.bias: requires_grad = True\n",
      "blocks.6.1.conv_pwl.weight: requires_grad = True\n",
      "blocks.6.1.bn3.weight: requires_grad = True\n",
      "blocks.6.1.bn3.bias: requires_grad = True\n",
      "conv_head.weight: requires_grad = True\n",
      "bn2.weight: requires_grad = True\n",
      "bn2.bias: requires_grad = True\n",
      "classifier.weight: requires_grad = True\n",
      "classifier.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_model_efficientnet(num_classes=2, num_freeze_layers=1):\n",
    "    \"\"\"\n",
    "    Creates an EfficientNet-B3 model with pretrained weights.\n",
    "    \n",
    "    EfficientNet models in timm have a `blocks` attribute.\n",
    "    This function freezes the early blocks and leaves the last `num_freeze_layers`\n",
    "    unfrozen. For example, using num_freeze_layers=1 means only the very last block\n",
    "    (plus the classifier head) will be trainable.\n",
    "    \n",
    "    Parameters:\n",
    "      - num_classes (int): number of output classes.\n",
    "      - num_freeze_layers (int): number of blocks to leave trainable starting from the end.\n",
    "    \n",
    "    Returns:\n",
    "      - model (nn.Module): The modified EfficientNet-B3 model.\n",
    "    \"\"\"\n",
    "    model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    if hasattr(model, 'blocks'):\n",
    "        total_blocks = len(model.blocks)\n",
    "        # Freeze blocks from 0 to total_blocks - num_freeze_layers.\n",
    "        for i in range(total_blocks - num_freeze_layers):\n",
    "            for param in model.blocks[i].parameters():\n",
    "                param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "# Set the number of blocks to keep trainable.\n",
    "num_freeze_layers = 1\n",
    "\n",
    "# Initialize EfficientNet-B3 model.\n",
    "efficientnet_model = get_model_efficientnet(num_classes=2, num_freeze_layers=num_freeze_layers)\n",
    "\n",
    "# Example: Print out which parameters are trainable.\n",
    "print(\"EfficientNet-B3 trainable parameters:\")\n",
    "for name, param in efficientnet_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6b30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT trainable parameters:\n",
      "cls_token: requires_grad = True\n",
      "pos_embed: requires_grad = True\n",
      "patch_embed.proj.weight: requires_grad = False\n",
      "patch_embed.proj.bias: requires_grad = False\n",
      "blocks.0.norm1.weight: requires_grad = False\n",
      "blocks.0.norm1.bias: requires_grad = False\n",
      "blocks.0.attn.qkv.weight: requires_grad = False\n",
      "blocks.0.attn.qkv.bias: requires_grad = False\n",
      "blocks.0.attn.proj.weight: requires_grad = False\n",
      "blocks.0.attn.proj.bias: requires_grad = False\n",
      "blocks.0.norm2.weight: requires_grad = False\n",
      "blocks.0.norm2.bias: requires_grad = False\n",
      "blocks.0.mlp.fc1.weight: requires_grad = False\n",
      "blocks.0.mlp.fc1.bias: requires_grad = False\n",
      "blocks.0.mlp.fc2.weight: requires_grad = False\n",
      "blocks.0.mlp.fc2.bias: requires_grad = False\n",
      "blocks.1.norm1.weight: requires_grad = False\n",
      "blocks.1.norm1.bias: requires_grad = False\n",
      "blocks.1.attn.qkv.weight: requires_grad = False\n",
      "blocks.1.attn.qkv.bias: requires_grad = False\n",
      "blocks.1.attn.proj.weight: requires_grad = False\n",
      "blocks.1.attn.proj.bias: requires_grad = False\n",
      "blocks.1.norm2.weight: requires_grad = False\n",
      "blocks.1.norm2.bias: requires_grad = False\n",
      "blocks.1.mlp.fc1.weight: requires_grad = False\n",
      "blocks.1.mlp.fc1.bias: requires_grad = False\n",
      "blocks.1.mlp.fc2.weight: requires_grad = False\n",
      "blocks.1.mlp.fc2.bias: requires_grad = False\n",
      "blocks.2.norm1.weight: requires_grad = False\n",
      "blocks.2.norm1.bias: requires_grad = False\n",
      "blocks.2.attn.qkv.weight: requires_grad = False\n",
      "blocks.2.attn.qkv.bias: requires_grad = False\n",
      "blocks.2.attn.proj.weight: requires_grad = False\n",
      "blocks.2.attn.proj.bias: requires_grad = False\n",
      "blocks.2.norm2.weight: requires_grad = False\n",
      "blocks.2.norm2.bias: requires_grad = False\n",
      "blocks.2.mlp.fc1.weight: requires_grad = False\n",
      "blocks.2.mlp.fc1.bias: requires_grad = False\n",
      "blocks.2.mlp.fc2.weight: requires_grad = False\n",
      "blocks.2.mlp.fc2.bias: requires_grad = False\n",
      "blocks.3.norm1.weight: requires_grad = False\n",
      "blocks.3.norm1.bias: requires_grad = False\n",
      "blocks.3.attn.qkv.weight: requires_grad = False\n",
      "blocks.3.attn.qkv.bias: requires_grad = False\n",
      "blocks.3.attn.proj.weight: requires_grad = False\n",
      "blocks.3.attn.proj.bias: requires_grad = False\n",
      "blocks.3.norm2.weight: requires_grad = False\n",
      "blocks.3.norm2.bias: requires_grad = False\n",
      "blocks.3.mlp.fc1.weight: requires_grad = False\n",
      "blocks.3.mlp.fc1.bias: requires_grad = False\n",
      "blocks.3.mlp.fc2.weight: requires_grad = False\n",
      "blocks.3.mlp.fc2.bias: requires_grad = False\n",
      "blocks.4.norm1.weight: requires_grad = False\n",
      "blocks.4.norm1.bias: requires_grad = False\n",
      "blocks.4.attn.qkv.weight: requires_grad = False\n",
      "blocks.4.attn.qkv.bias: requires_grad = False\n",
      "blocks.4.attn.proj.weight: requires_grad = False\n",
      "blocks.4.attn.proj.bias: requires_grad = False\n",
      "blocks.4.norm2.weight: requires_grad = False\n",
      "blocks.4.norm2.bias: requires_grad = False\n",
      "blocks.4.mlp.fc1.weight: requires_grad = False\n",
      "blocks.4.mlp.fc1.bias: requires_grad = False\n",
      "blocks.4.mlp.fc2.weight: requires_grad = False\n",
      "blocks.4.mlp.fc2.bias: requires_grad = False\n",
      "blocks.5.norm1.weight: requires_grad = False\n",
      "blocks.5.norm1.bias: requires_grad = False\n",
      "blocks.5.attn.qkv.weight: requires_grad = False\n",
      "blocks.5.attn.qkv.bias: requires_grad = False\n",
      "blocks.5.attn.proj.weight: requires_grad = False\n",
      "blocks.5.attn.proj.bias: requires_grad = False\n",
      "blocks.5.norm2.weight: requires_grad = False\n",
      "blocks.5.norm2.bias: requires_grad = False\n",
      "blocks.5.mlp.fc1.weight: requires_grad = False\n",
      "blocks.5.mlp.fc1.bias: requires_grad = False\n",
      "blocks.5.mlp.fc2.weight: requires_grad = False\n",
      "blocks.5.mlp.fc2.bias: requires_grad = False\n",
      "blocks.6.norm1.weight: requires_grad = False\n",
      "blocks.6.norm1.bias: requires_grad = False\n",
      "blocks.6.attn.qkv.weight: requires_grad = False\n",
      "blocks.6.attn.qkv.bias: requires_grad = False\n",
      "blocks.6.attn.proj.weight: requires_grad = False\n",
      "blocks.6.attn.proj.bias: requires_grad = False\n",
      "blocks.6.norm2.weight: requires_grad = False\n",
      "blocks.6.norm2.bias: requires_grad = False\n",
      "blocks.6.mlp.fc1.weight: requires_grad = False\n",
      "blocks.6.mlp.fc1.bias: requires_grad = False\n",
      "blocks.6.mlp.fc2.weight: requires_grad = False\n",
      "blocks.6.mlp.fc2.bias: requires_grad = False\n",
      "blocks.7.norm1.weight: requires_grad = False\n",
      "blocks.7.norm1.bias: requires_grad = False\n",
      "blocks.7.attn.qkv.weight: requires_grad = False\n",
      "blocks.7.attn.qkv.bias: requires_grad = False\n",
      "blocks.7.attn.proj.weight: requires_grad = False\n",
      "blocks.7.attn.proj.bias: requires_grad = False\n",
      "blocks.7.norm2.weight: requires_grad = False\n",
      "blocks.7.norm2.bias: requires_grad = False\n",
      "blocks.7.mlp.fc1.weight: requires_grad = False\n",
      "blocks.7.mlp.fc1.bias: requires_grad = False\n",
      "blocks.7.mlp.fc2.weight: requires_grad = False\n",
      "blocks.7.mlp.fc2.bias: requires_grad = False\n",
      "blocks.8.norm1.weight: requires_grad = False\n",
      "blocks.8.norm1.bias: requires_grad = False\n",
      "blocks.8.attn.qkv.weight: requires_grad = False\n",
      "blocks.8.attn.qkv.bias: requires_grad = False\n",
      "blocks.8.attn.proj.weight: requires_grad = False\n",
      "blocks.8.attn.proj.bias: requires_grad = False\n",
      "blocks.8.norm2.weight: requires_grad = False\n",
      "blocks.8.norm2.bias: requires_grad = False\n",
      "blocks.8.mlp.fc1.weight: requires_grad = False\n",
      "blocks.8.mlp.fc1.bias: requires_grad = False\n",
      "blocks.8.mlp.fc2.weight: requires_grad = False\n",
      "blocks.8.mlp.fc2.bias: requires_grad = False\n",
      "blocks.9.norm1.weight: requires_grad = False\n",
      "blocks.9.norm1.bias: requires_grad = False\n",
      "blocks.9.attn.qkv.weight: requires_grad = False\n",
      "blocks.9.attn.qkv.bias: requires_grad = False\n",
      "blocks.9.attn.proj.weight: requires_grad = False\n",
      "blocks.9.attn.proj.bias: requires_grad = False\n",
      "blocks.9.norm2.weight: requires_grad = False\n",
      "blocks.9.norm2.bias: requires_grad = False\n",
      "blocks.9.mlp.fc1.weight: requires_grad = False\n",
      "blocks.9.mlp.fc1.bias: requires_grad = False\n",
      "blocks.9.mlp.fc2.weight: requires_grad = False\n",
      "blocks.9.mlp.fc2.bias: requires_grad = False\n",
      "blocks.10.norm1.weight: requires_grad = False\n",
      "blocks.10.norm1.bias: requires_grad = False\n",
      "blocks.10.attn.qkv.weight: requires_grad = False\n",
      "blocks.10.attn.qkv.bias: requires_grad = False\n",
      "blocks.10.attn.proj.weight: requires_grad = False\n",
      "blocks.10.attn.proj.bias: requires_grad = False\n",
      "blocks.10.norm2.weight: requires_grad = False\n",
      "blocks.10.norm2.bias: requires_grad = False\n",
      "blocks.10.mlp.fc1.weight: requires_grad = False\n",
      "blocks.10.mlp.fc1.bias: requires_grad = False\n",
      "blocks.10.mlp.fc2.weight: requires_grad = False\n",
      "blocks.10.mlp.fc2.bias: requires_grad = False\n",
      "blocks.11.norm1.weight: requires_grad = True\n",
      "blocks.11.norm1.bias: requires_grad = True\n",
      "blocks.11.attn.qkv.weight: requires_grad = True\n",
      "blocks.11.attn.qkv.bias: requires_grad = True\n",
      "blocks.11.attn.proj.weight: requires_grad = True\n",
      "blocks.11.attn.proj.bias: requires_grad = True\n",
      "blocks.11.norm2.weight: requires_grad = True\n",
      "blocks.11.norm2.bias: requires_grad = True\n",
      "blocks.11.mlp.fc1.weight: requires_grad = True\n",
      "blocks.11.mlp.fc1.bias: requires_grad = True\n",
      "blocks.11.mlp.fc2.weight: requires_grad = True\n",
      "blocks.11.mlp.fc2.bias: requires_grad = True\n",
      "norm.weight: requires_grad = True\n",
      "norm.bias: requires_grad = True\n",
      "head.weight: requires_grad = True\n",
      "head.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_model_vit(num_classes=2, num_freeze_layers=1):\n",
    "    \"\"\"\n",
    "    Creates a Vision Transformer (ViT) model with pretrained weights.\n",
    "    \n",
    "    This function freezes the first transformer blocks (and, if desired, the patch embedding)\n",
    "    so that only the last `num_freeze_layers` blocks (plus the classification head) remain trainable.\n",
    "    \n",
    "    Parameters:\n",
    "      - num_classes (int): number of output classes.\n",
    "      - num_freeze_layers (int): number of transformer blocks (starting from the end)\n",
    "                                 to keep trainable.\n",
    "    \n",
    "    Returns:\n",
    "      - model (nn.Module): The modified ViT model.\n",
    "    \"\"\"\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    if hasattr(model, 'blocks'):\n",
    "        total_blocks = len(model.blocks)\n",
    "        # Freeze transformer blocks from 0 to (total_blocks - num_freeze_layers)\n",
    "        for i in range(total_blocks - num_freeze_layers):\n",
    "            for param in model.blocks[i].parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Optionally, freeze the initial patch embedding if desired.\n",
    "        if hasattr(model, 'patch_embed'):\n",
    "            for param in model.patch_embed.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "    return model\n",
    "\n",
    "# Set the number of transformer blocks to keep trainable.\n",
    "num_freeze_layers = 1\n",
    "\n",
    "# Initialize ViT model.\n",
    "vit_model = get_model_vit(num_classes=2, num_freeze_layers=num_freeze_layers)\n",
    "\n",
    "# Example: Print out which parameters are trainable.\n",
    "print(\"ViT trainable parameters:\")\n",
    "for name, param in vit_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1299687b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7729b45affd0477f8d305ab4efaff541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  15%|#4        | 52.4M/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m num_freeze_layers = \u001b[32m1\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Initialize ConvNeXt model.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m convnext_model = \u001b[43mget_model_convnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_freeze_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_freeze_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Example: Print out which parameters are trainable.\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConvNeXt trainable parameters:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mget_model_convnext\u001b[39m\u001b[34m(num_classes, num_freeze_layers)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model_convnext\u001b[39m(num_classes=\u001b[32m2\u001b[39m, num_freeze_layers=\u001b[32m1\u001b[39m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Creates a ConvNeXt Base model with pretrained weights.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;03m      - model (nn.Module): The modified ConvNeXt model.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     model = \u001b[43mtimm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconvnext_base\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mblocks\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     19\u001b[39m         total_blocks = \u001b[38;5;28mlen\u001b[39m(model.blocks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/timm/models/_factory.py:126\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m create_fn = model_entrypoint(model_name)\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable=scriptable, exportable=exportable, no_jit=no_jit):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     model = \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[32m    135\u001b[39m     load_checkpoint(model, checkpoint_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/timm/models/convnext.py:1114\u001b[39m, in \u001b[36mconvnext_base\u001b[39m\u001b[34m(pretrained, **kwargs)\u001b[39m\n\u001b[32m   1111\u001b[39m \u001b[38;5;129m@register_model\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvnext_base\u001b[39m(pretrained=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> ConvNeXt:\n\u001b[32m   1113\u001b[39m     model_args = \u001b[38;5;28mdict\u001b[39m(depths=[\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m27\u001b[39m, \u001b[32m3\u001b[39m], dims=[\u001b[32m128\u001b[39m, \u001b[32m256\u001b[39m, \u001b[32m512\u001b[39m, \u001b[32m1024\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m     model = \u001b[43m_create_convnext\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconvnext_base\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/timm/models/convnext.py:573\u001b[39m, in \u001b[36m_create_convnext\u001b[39m\u001b[34m(variant, pretrained, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mpretrained_cfg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) == \u001b[33m'\u001b[39m\u001b[33mfcmae\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# NOTE fcmae pretrained weights have no classifier or final norm-layer (`head.norm`)\u001b[39;00m\n\u001b[32m    570\u001b[39m     \u001b[38;5;66;03m# This is workaround loading with num_classes=0 w/o removing norm-layer.\u001b[39;00m\n\u001b[32m    571\u001b[39m     kwargs.setdefault(\u001b[33m'\u001b[39m\u001b[33mpretrained_strict\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m model = \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mConvNeXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_sequential\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/timm/models/_builder.py:436\u001b[39m, in \u001b[36mbuild_model_with_cfg\u001b[39m\u001b[34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, cache_dir, kwargs_filter, **kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m num_classes_pretrained = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, kwargs.get(\u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m))\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43min_chans\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/timm/models/_builder.py:213\u001b[39m, in \u001b[36mload_pretrained\u001b[39m\u001b[34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict, cache_dir)\u001b[39m\n\u001b[32m    211\u001b[39m             state_dict = load_state_dict_from_hf(*pretrained_loc, cache_dir=cache_dir)\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m         state_dict = \u001b[43mload_state_dict_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     model_name = pretrained_cfg.get(\u001b[33m'\u001b[39m\u001b[33marchitecture\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mthis model\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/timm/models/_hub.py:211\u001b[39m, in \u001b[36mload_state_dict_from_hf\u001b[39m\u001b[34m(model_id, filename, weights_only, cache_dir)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m safe_filename \u001b[38;5;129;01min\u001b[39;00m _get_safe_alternatives(filename):\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         cached_safe_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m         _logger.info(\n\u001b[32m    218\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Safe alternative available for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(as \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msafe_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m). Loading weights using safetensors.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m safetensors.torch.load_file(cached_safe_file, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:961\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    941\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    942\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    943\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m         local_files_only=local_files_only,\n\u001b[32m    959\u001b[39m     )\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1112\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1110\u001b[39m Path(lock_path).parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1125\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1675\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1669\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1670\u001b[39m             logger.warning(\n\u001b[32m   1671\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1672\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1673\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1675\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1680\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1682\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1684\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1685\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:449\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    447\u001b[39m new_resume_size = resume_size\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[32m    451\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/PyTorch/PyTorch_Projects/.venv/lib/python3.13/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def get_model_convnext(num_classes=2, num_freeze_layers=1):\n",
    "    \"\"\"\n",
    "    Creates a ConvNeXt Base model with pretrained weights.\n",
    "    \n",
    "    ConvNeXt models have a list of blocks in the `blocks` attribute.\n",
    "    The function freezes all blocks except the last `num_freeze_layers` blocks, so you can\n",
    "    experiment with how many blocks you want unfrozen.\n",
    "    \n",
    "    Parameters:\n",
    "      - num_classes (int): number of output classes.\n",
    "      - num_freeze_layers (int): number of blocks (from the end) to keep trainable.\n",
    "    \n",
    "    Returns:\n",
    "      - model (nn.Module): The modified ConvNeXt model.\n",
    "    \"\"\"\n",
    "    model = timm.create_model('convnext_base', pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    if hasattr(model, 'blocks'):\n",
    "        total_blocks = len(model.blocks)\n",
    "        for i in range(total_blocks - num_freeze_layers):\n",
    "            for param in model.blocks[i].parameters():\n",
    "                param.requires_grad = False\n",
    "    return model\n",
    "  \n",
    "# Set the number of blocks to keep trainable.\n",
    "num_freeze_layers = 1\n",
    "\n",
    "# Initialize ConvNeXt model.\n",
    "convnext_model = get_model_convnext(num_classes=2, num_freeze_layers=num_freeze_layers)\n",
    "\n",
    "# Example: Print out which parameters are trainable.\n",
    "print(\"ConvNeXt trainable parameters:\")\n",
    "for name, param in convnext_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4db28",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b457fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3012ecaa3db04fdbabca21ce2e13e94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | Epoch 0/3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d230774d54a46a5867873a1de561af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/594 batches"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cad715804a41858424f256bbffd300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 batches"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.1890, Train Acc: 0.9200, Val Loss: 0.1454, Val Acc: 0.9445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6352747c76f44297b2bd156b7d661832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/594 batches"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234ddb083290405c89042827d0a169e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 batches"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0907, Train Acc: 0.9645, Val Loss: 0.1033, Val Acc: 0.9590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2f8aec712a450fbbf1cd28d23fd1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/594 batches"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a82c3913b8c44f8afc2abeb38dc7ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 batches"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0566, Train Acc: 0.9778, Val Loss: 0.0966, Val Acc: 0.9645\n",
      "\n",
      "Unfreezing the last block for fine-tuning...\n",
      "Training complete!\n",
      "{'train_loss': [0.18897588282811006, 0.09066420299443843, 0.05662003038786564], 'train_acc': [0.9200416052243522, 0.9644775647777544, 0.977814935748894], 'val_loss': [0.14542651694527026, 0.10333264374983436, 0.09664682483392814], 'val_acc': [0.9444722361180591, 0.9589794897448725, 0.9644822411205602]}\n"
     ]
    }
   ],
   "source": [
    "# Import the train_model function from our module.\n",
    "from going_modular.train_model import train_model\n",
    "\n",
    "# Import necessary libraries.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Move model to the appropriate device.\n",
    "vit_model = vit_model.to(device)\n",
    "\n",
    "# Define the loss function.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer. Only update parameters that require grad.\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, vit_model.parameters()), lr=1e-4)\n",
    "\n",
    "# Define a learning rate scheduler (for example, a StepLR that reduces LR every 5 epochs by 50%).\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "# Now, call the train_model function to train the model.\n",
    "history = train_model(model=vit_model,\n",
    "                      train_loader=train_loader,\n",
    "                      val_loader=val_loader,\n",
    "                      loss_fn=loss_fn,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      epochs=3,\n",
    "                      device=device,\n",
    "                      base_lr=1e-4,\n",
    "                      patience=3,\n",
    "                      unfreeze_epoch=3,\n",
    "                      unfreeze_option=\"last\")\n",
    "\n",
    "# Print the training history to summarize the results.\n",
    "print(\"Training complete!\")\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d6e364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell: Plot loss/accuracy curves and compute F1, precision, recall on validation set\n",
    "\n",
    "# 1. Import what we need\n",
    "from helper_functions import plot_loss_curves\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch\n",
    "\n",
    "# 2. Prepare the results dict for plotting (helper expects keys: train_loss, test_loss, train_acc, test_acc)\n",
    "results = {\n",
    "    \"train_loss\": history[\"train_loss\"],\n",
    "    \"test_loss\":  history[\"val_loss\"],\n",
    "    \"train_acc\":  history[\"train_acc\"],\n",
    "    \"test_acc\":   history[\"val_acc\"]\n",
    "}\n",
    "\n",
    "# 3. Plot loss and accuracy curves\n",
    "plot_loss_curves(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc697c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Precision: 0.9765\n",
      "Validation Recall:    0.9575\n",
      "Validation F1 Score:  0.9669\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Compute predictions on the validation set\n",
    "vit_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for X, y in val_loader:\n",
    "        X = X.to(device)\n",
    "        logits = vit_model(X)\n",
    "        # get probability for class â€œ1â€ (AI-generated) via softmax\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        # threshold at 0.5\n",
    "        preds = (probs >= 0.5).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(y.numpy())\n",
    "\n",
    "# 5. Calculate precision, recall, and F1-score\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall    = recall_score(all_labels, all_preds)\n",
    "f1        = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall:    {recall:.4f}\")\n",
    "print(f\"Validation F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1963a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CSV sample:\n",
      "                                                  id\n",
      "0  test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg\n",
      "1  test_data_v2/ab5df8f441fe4fbf9dc9c6baae699dc7.jpg\n",
      "2  test_data_v2/eb364dd2dfe34feda0e52466b7ce7956.jpg\n",
      "3  test_data_v2/f76c2580e9644d85a741a42c6f6b39c0.jpg\n",
      "4  test_data_v2/a16495c578b7494683805484ca27cf9f.jpg\n"
     ]
    }
   ],
   "source": [
    "# Cell: Generate submission.csv using the 'id' column directly as the image path\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Read test.csv\n",
    "test_csv_path = os.path.join(base_dir, \"test.csv\")\n",
    "df_test       = pd.read_csv(test_csv_path)  # expects an 'id' column\n",
    "print(\"Test CSV sample:\")\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "772503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Dataset that treats each 'id' as the relative path from base_dir\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, df, base_dir, transform=None):\n",
    "        \"\"\"\n",
    "        df: DataFrame with an 'id' column whose entries are paths\n",
    "            like 'test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg'\n",
    "        base_dir: the root folder containing test_data_v2\n",
    "        transform: validation transforms\n",
    "        \"\"\"\n",
    "        self.df      = df.reset_index(drop=True)\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row    = self.df.iloc[idx]\n",
    "        id_val = row[\"id\"]\n",
    "        img_path = os.path.join(self.base_dir, id_val)\n",
    "        image    = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, id_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f894ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Create DataLoader with num_workers=0\n",
    "test_dataset = TestImageDataset(df_test, base_dir, transform=val_transform)\n",
    "test_loader  = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,    # avoid pickling issues\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fbbc68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ submission.csv saved (columns: id, label)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Run inference and collect ids & predictions\n",
    "vit_model.eval()\n",
    "ids_out, preds_out = [], []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for imgs, ids in test_loader:\n",
    "        imgs   = imgs.to(device)\n",
    "        logits = vit_model(imgs)\n",
    "        probs  = torch.softmax(logits, dim=1)[:, 1]\n",
    "        preds  = (probs >= 0.5).long().cpu().numpy()\n",
    "        ids_out.extend(ids)        # ids are strings like 'test_data_v2/xxx.jpg'\n",
    "        preds_out.extend(preds)\n",
    "\n",
    "# 5. Build submission DataFrameâ€”strip any directory prefix if needed\n",
    "#    Here we assume the competition expects exactly the same 'id' strings.\n",
    "submission = pd.DataFrame({\n",
    "    \"id\":    ids_out,\n",
    "    \"label\": preds_out\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"â†’ submission.csv saved (columns: id, label)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6dc056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: create the folder structure\n",
    "import os\n",
    "\n",
    "base = \"demos/ai-vs-human-pictures\"\n",
    "os.makedirs(os.path.join(base, \"models\"),      exist_ok=True)\n",
    "os.makedirs(os.path.join(base, \"examples/ai\"),     exist_ok=True)\n",
    "os.makedirs(os.path.join(base, \"examples/non-ai\"), exist_ok=True)\n",
    "# we'll put model.pth in demos/.../models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3cc4413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to demos/ai-vs-human-pictures/models/model.pth\n"
     ]
    }
   ],
   "source": [
    "# Cell: save your ViT weights\n",
    "import torch\n",
    "\n",
    "# move to CPU just in case\n",
    "vit_model = vit_model.to(\"cpu\")\n",
    "torch.save(vit_model.state_dict(), \"demos/ai-vs-human-pictures/models/model.pth\")\n",
    "print(\"Model saved to demos/ai-vs-human-pictures/models/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39feb5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 10 AI images and 10 human images into demos/ai-vs-human-pictures/examples/\n"
     ]
    }
   ],
   "source": [
    "# Cell: copy 10 AI and 10 human images from your train split\n",
    "import os, shutil, pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/detect-ai-vs-human-generated-images/train.csv\")\n",
    "base_dir = \"data/detect-ai-vs-human-generated-images\"\n",
    "\n",
    "# pick the first 10 of each class\n",
    "ai_imgs    = df[df.label == 1].head(10)[\"file_name\"].tolist()\n",
    "human_imgs = df[df.label == 0].head(10)[\"file_name\"].tolist()\n",
    "\n",
    "for fn in ai_imgs:\n",
    "    src = os.path.join(base_dir, fn)\n",
    "    dst = os.path.join(\"demos/ai-vs-human-pictures/examples/ai\", os.path.basename(fn))\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "for fn in human_imgs:\n",
    "    src = os.path.join(base_dir, fn)\n",
    "    dst = os.path.join(\"demos/ai-vs-human-pictures/examples/non-ai\", os.path.basename(fn))\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "print(\"Copied 10 AI images and 10 human images into demos/ai-vs-human-pictures/examples/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "015fde66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI examples:\n",
      "['a02c596a83164f82b794b1b67ff7bcec.jpg', 'fc9dbe25e2d54014a7fafd53198632f5.jpg', '774aeb00dbf44520bf3be78bb600bda9.jpg', 'a6dcb93f596a43249135678dfcfc17ea.jpg', '615df26ce9494e5db2f70e57ce7a3a4f.jpg', '5d81fa12bc3b4cea8c94a6700a477cf2.jpg', '340014208f2e46afb5fb1b0837bf52cf.jpg', 'dea116642f354126b79d048de24010e3.jpg', 'e67085fb6d814cbabe08f978c738f3f7.jpg', '4aea3b876247467c8d3713d4920148ab.jpg']\n",
      "\n",
      "Human examples:\n",
      "['91f5e18cdfde4d6b929561f4ec150bbf.jpg', '8542fe161d9147be8e835e50c0de39cd.jpg', '041be3153810433ab146bc97d5af505c.jpg', '33a6a93ef8074ef684291557a00a408b.jpg', '6b1b4ec385c346cdb4b5c6e74837df2b.jpg', '09708379751e44d0bc908d8652d0db3e.jpg', '25ea852f30594bc5915eb929682af429.jpg', '041c36d9269146cdb88e7526e3b91651.jpg', 'c098c9452c6748ca8d94134d898da05a.jpg', '2275dc00b50f4183812b5c3930365598.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Cell: list out the example filenames\n",
    "import os\n",
    "\n",
    "ai_folder    = \"demos/ai-vs-human-pictures/examples/ai\"\n",
    "human_folder = \"demos/ai-vs-human-pictures/examples/non-ai\"\n",
    "\n",
    "print(\"AI examples:\")\n",
    "print(os.listdir(ai_folder))\n",
    "print(\"\\nHuman examples:\")\n",
    "print(os.listdir(human_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "590341b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing demos/ai-vs-human-pictures/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile demos/ai-vs-human-pictures/requirements.txt\n",
    "torch\n",
    "torchvision\n",
    "timm\n",
    "gradio\n",
    "Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d4d6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import timm\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# â€” determine base directory â€”\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).parent\n",
    "except NameError:\n",
    "    # when running in a notebook\n",
    "    BASE_DIR = Path.cwd() / \"demos\" / \"ai-vs-human-pictures\"\n",
    "\n",
    "MODEL_PATH    = BASE_DIR / \"models\" / \"model.pth\"\n",
    "EXAMPLES_DIR  = BASE_DIR / \"examples\"\n",
    "AI_DIR        = EXAMPLES_DIR / \"ai\"\n",
    "HUMAN_DIR     = EXAMPLES_DIR / \"non-ai\"\n",
    "\n",
    "# â€” load model â€”\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=2)\n",
    "checkpoint = torch.load(MODEL_PATH, map_location='cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# â€” preprocessing (same as validation) â€”\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# â€” build example list: alternate AI / human â€”\n",
    "ai_images    = sorted(AI_DIR.glob(\"*.*\"))\n",
    "human_images = sorted(HUMAN_DIR.glob(\"*.*\"))\n",
    "examples = []\n",
    "for ai_img, human_img in zip(ai_images, human_images):\n",
    "    examples.append([str(ai_img)])\n",
    "    examples.append([str(human_img)])\n",
    "\n",
    "# â€” inference function â€”\n",
    "def classify(image):\n",
    "    img    = image.convert(\"RGB\")\n",
    "    batch  = val_transform(img).unsqueeze(0)\n",
    "    with torch.inference_mode():\n",
    "        logits = model(batch)\n",
    "        probs  = torch.softmax(logits, dim=1)[0].tolist()\n",
    "    return {\"Human\": probs[0], \"AI\": probs[1]}\n",
    "\n",
    "# â€” Gradio interface â€”\n",
    "demo = gr.Interface(\n",
    "    fn=classify,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    examples=examples,\n",
    "    examples_per_page=20,\n",
    "    title=\"AI vs Human Image Detector\",\n",
    "    description=\"Upload an image or click one of the 20 examples below to see P(Human) vs. P(AI).\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demos/ai-vs-human-pictures/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demos/ai-vs-human-pictures/app.py\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import timm\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# â€” determine base directory â€”\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).parent\n",
    "except NameError:\n",
    "    # when running in a notebook\n",
    "    BASE_DIR = Path.cwd() / \"demos\" / \"ai-vs-human-pictures\"\n",
    "\n",
    "MODEL_PATH    = BASE_DIR / \"models\" / \"model.pth\"\n",
    "EXAMPLES_DIR  = BASE_DIR / \"examples\"\n",
    "AI_DIR        = EXAMPLES_DIR / \"ai\"\n",
    "HUMAN_DIR     = EXAMPLES_DIR / \"non-ai\"\n",
    "\n",
    "# â€” load model â€”\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=2)\n",
    "checkpoint = torch.load(MODEL_PATH, map_location='cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# â€” preprocessing (same as validation) â€”\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# â€” build example list: alternate AI / human â€”\n",
    "ai_images    = sorted(AI_DIR.glob(\"*.*\"))\n",
    "human_images = sorted(HUMAN_DIR.glob(\"*.*\"))\n",
    "examples = []\n",
    "for ai_img, human_img in zip(ai_images, human_images):\n",
    "    examples.append([str(ai_img)])\n",
    "    examples.append([str(human_img)])\n",
    "\n",
    "# â€” inference function â€”\n",
    "def classify(image):\n",
    "    img    = image.convert(\"RGB\")\n",
    "    batch  = val_transform(img).unsqueeze(0)\n",
    "    with torch.inference_mode():\n",
    "        logits = model(batch)\n",
    "        probs  = torch.softmax(logits, dim=1)[0].tolist()\n",
    "    return {\"Human\": probs[0], \"AI\": probs[1]}\n",
    "\n",
    "# â€” Gradio interface â€”\n",
    "demo = gr.Interface(\n",
    "    fn=classify,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    examples=examples,\n",
    "    examples_per_page=20,\n",
    "    title=\"AI vs Human Image Detector\",\n",
    "    description=\"Upload an image or click one of the 20 examples below to see whether it is an AI-generated image or a real image!\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e423af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
